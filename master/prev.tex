\chapter{関連研究}
\label{chap:related_work}

\section{プログラミングにおける誤答分析}
プログラミング教育において,学習者の解答コードを分析・分類する手法は,長年研究されてきた.これまでの研究におけるアプローチは,大きく分けて「構造的アプローチ」「意味的アプローチ」「動的・深層学習アプローチ」の3つに大別される.

まず,\textbf{構造的アプローチ}は,ソースコードのテキストや抽象構文木（以下AST）などの構文情報に着目する手法である.初期の研究ではテキストマイニング技術が用いられ,その後,木編集距離を用いた手法などが提案された.しかし,これらはインデントや変数名の違いといった表層的な変更に敏感であり,本質的なロジックの類似性を捉えにくいという課題があった.

次に,\textbf{意味的アプローチ}は,制御フローグラフ（以下CFG）やデータフローグラフ（以下DFG）を用いて,コードの動作やデータの流れといった「プログラムの意味」に着目する手法である.このアプローチはアルゴリズム的な戦略を捉えるのに適するが,グラフ間の同型性判定や編集距離計算など,計算コストが高くなる傾向にある.

最後に,\textbf{動的・深層学習アプローチ}は,実行時のトレース情報や機械学習モデルを活用する手法である.記述形式に依存しない柔軟な分類が可能であるが,大量の学習データの収集や,モデルごとの前処理が必要となる点が課題とされる.

次節以降では,本研究のアプローチと特に関連の深い,機械学習・LLMを用いた手法および,グラフ構造を用いた分類手法について詳述する.

\section{機械学習およびLLMを用いたコード分類}
近年では,機械学習や大規模言語モデル（以下, LLM）を用いてソースコードの特徴をベクトル空間へ埋め込み,分類を行う研究が進められている.

\subsection{機械学習による分類モデル}
深層学習を用いたソースコード解析の分野では, 藤原ら\cite{fujiwara2022}による研究が挙げられる. 彼らは, LSTMやGCNといったニューラルネットワークを用いてソースコードの特徴を学習し, 「ソースコード分類」と「コードクローン検出」の双方に取り組んでいる. ソースコード分類が単一のコード片を入力とし, その機能や属性のクラスを予測するタスクであるのに対し, コードクローン検出は2つのコード片を入力とし, その間の類似性や等価性を判定するタスクである. これらは入力形式や出力層の設計においては異なるアプローチをとるが, 深層学習モデルがコードの構文的・意味的特徴を捉える必要があるという点では本質的に同義である.

藤原らは, 従来のモデルが特定の学習データセットの特性に過剰に適合してしまう「データセット依存」の問題に着目した. 特にコードクローン検出において, 判定タスクを単純な2値分類から, ASTの類似度を予測する「回帰モデル」へと再定義することで, 未知のデータに対する汎化性能を向上させている.

しかしながら, 分類と検出のいずれのタスクであっても, こうした教師あり学習に基づく手法は, モデルの構築にあたり, 正解ラベルが付与された大量かつ高品質な学習データを必要とする点に変わりはない. プログラミング教育の現場において, 学習者が生成する多種多様な誤答コードに対し, 事前に網羅的なラベル付きデータを用意することはコスト的に困難である. また, モデルは学習した特徴空間内での判定には長けているが, 学習データに含まれない未知の論理的誤りや, 文脈に深く依存した意図の汲み取りにおいては限界が存在する.


\subsection{LLM活用の可能性}
\label{subsec:llm_potential}
近年のLLMは,ソースコードの生成や解説,要約といったタスクにおいて高い性能を示す.
この高度な文脈理解能力に基づけば,自然言語による指示（プロンプト)を与えることで,LLMがソースコード中の論理的な誤りや意図を汲み取り,適切なカテゴリへ分類できる可能性が期待される.
% 特に,従来の機械学習モデルでは学習データの作成コストが高かった「意味的なカテゴリ」への分類において,LLMの持つゼロショット・フューショット能力は強力な選択肢となり得る.

しかし,これらの能力が厳密な分類タスクにおいてどの程度有効に機能するかは自明ではない.
LLMには確率的な出力による不安定さや,事実に基づかない回答を生成するハルシネーションのリスクが含まれるためである.
したがって,プログラミングエラーの分類という正確性が求められるタスクにおいて,LLMが単独で実用的な精度を達成できるかについては,慎重な検証が必要である.

\section{グラフ構造を用いたコード分類}
\label{sec:asanas_cluster}
機械学習モデルとは対照的に,プログラムの構造的・意味的特徴を明示的なグラフとして捉え,分類を行う研究として,PaivaらによるAsanas Clusterがある\cite{Asanas Cluster}.
本研究の提案手法では,このアプローチを基礎として採用するため,本節ではその核心となるグラフ表現の定義および,先行研究において示された有効性について述べる.

\subsection{CFGとDFGによる特徴表現}
Asanas Clusterの最大の特徴は,コードの表層的なテキストではなく,アルゴリズム的戦略を捉えるために以下の2つのグラフ表現を利用する点にある.

\begin{itemize}
    \item \textbf{制御フローグラフ (CFG)}:\\
    Paivaらは, CFGを有向グラフ $G=(N,E,n_{0},n_{f})$ と定義する. 
    ここで, $N=\{n_{1},n_{2},...\}\cup\{n_{0},n_{f}\}$ はノードの集合であり, プログラムの「基本ブロック」に対応する. 
    $E$ は有向エッジの集合であり, ノード間の制御依存関係を表す. 
    また, $n_{0}$ と $n_{f}$ はそれぞれ, 制御がグラフに入力される「入口ノード」と, 制御がグラフから出る「出口ノード」を表し, これらは各ノードの後続ノードが最大2つになるように追加される.
    CFGは, プログラム実行中に取りうる経路や分岐といった制御フローの振る舞いを捉える構造であり, コードの記述スタイルの影響を受けにくいという利点がある\cite{Asanas Cluster}.

    \item \textbf{データフローグラフ (DFG)}:\\
    DFGは, 有向グラフ $G=(N,E)$ と定義される. 
    ここで, $N=\{n_{1},n_{2},...\}$ はノードの集合であり, 個々の計算単位や命令を表す. 
    $E$ は有向エッジの集合であり, データ依存関係を表す. 
    具体的には, エッジ $(n_{i},n_{j})$ ($n_{i},n_{j}\in N$) は, ノード $n_{i}$ の出力データがノード $n_{j}$ によって消費されることを意味する. 
    制御フローだけでは同一に見えるコードでも, 変数の使い回しや計算順序の違いなどデータの処理順序や依存関係が異なる場合, DFGによってその差異を明確に識別することが可能となる\cite{Asanas Cluster}.
\end{itemize}

\vspace{4cm}

\subsection{アプローチ概要と分類精度の評価}
Paivaらは,これらのグラフ構造の全てを比較するのではなく,グラフから構造的な\textbf{特徴量を抽出し,ベクトル空間上でクラスタリングを行う}手法を提案した.

具体的には,CFGからプログラムの複雑さや制御構造を,DFGから変数の操作頻度などを数値化し,それらをK-means法によって分類する.また,教育現場での利用を想定し,提出物が届くたびにモデルを更新する「インクリメンタル学習」を採用する点が特徴である.

\begin{figure}[t]
    \centering
    % 画像ファイル名は適切に変更してください
    \includegraphics[width=0.9\textwidth]{src/asanas_pca_result.png}
    \caption{先行研究におけるクラスタリング結果のPCA可視化（左: グラフ探索, 右: ソートアルゴリズム） (出典: Paiva et al. \cite{Asanas Cluster})}
    \label{fig:asanas_pca_result_prev}
\end{figure}


この手法の有効性は,以下の2つのデータセットを用いた実験によって検証されている.

\begin{enumerate}
    \item \textbf{グラフ探索アルゴリズム:} アルゴリズム設計の授業において収集された,深さ優先探索 (DFS) と幅優先探索 (BFS) の実装（計100件）.
    \item \textbf{ソートアルゴリズム:} GitHubから収集された,異なる4種類のソートアルゴリズム（ヒープ,マージ,挿入,クイック）の実装（計100件）.
\end{enumerate}

実験の結果,この手法は\textbf{異なるアルゴリズム戦略を完全に分離することに成功する}（Error Index = 0）.
図\ref{fig:asanas_pca_result_prev}は,抽出された特徴ベクトルに対し主成分分析（PCA）を適用し,クラスタリング結果を2次元平面上に可視化したものである（出典：Paiva et al. \cite{Asanas Cluster}）.

左図はグラフ探索（2クラスタ）,右図はソートアルゴリズム（4クラスタ）の結果を示す.
図から明らかなように,\textbf{実装の詳細が異なるコードであっても,アルゴリズムの戦略が異なれば,特徴量空間上で明確に分離されたクラスタを形成する}ことが確認できる.


この結果は,CFGとDFGから抽出された特徴量が,コードの書き方ではなく「アルゴリズム」を捉えるのに十分な情報を有することを示唆する.

\section{本研究の位置づけ}
前節までに述べた関連研究の知見に基づき,本研究の立ち位置を明確にする.

PaivaらのAsanas Clusterは,図\ref{fig:asanas_pca_result_prev}に示した通り,正答コードにおける「アルゴリズム的戦略」の違いを明確にクラスタリングすることに成功する\cite{Asanas Cluster}.
本研究では,この\textbf{「コードの構造的な差異を捉える能力」が,誤答コードの分類にも応用可能である}という仮説に基づく.

誤答コードにおいても,その誤りの種類（ロジックの欠陥,ループ条件の誤り,変数の誤用など）によって,生成されるCFGやデータフローには特有の構造的特徴が現れる可能性が高い.
したがって,本研究ではAsanas Clusterで有効性が示された特徴抽出アプローチを「誤答コードの分類」というタスクに応用し,異なる誤りパターンを自動的に分離できるかを検証する.

その上で,第\ref{subsec:llm_potential}節で述べたLLMを用いた意味的な分類アプローチと比較を行うことで,誤答分析における最適な手法を明らかにする.
