\chapter{誤答分類実験}
\label{chap:methodology}

\section{実験目的}
本研究の目的は,プログラミング演習における誤答ソースコードを機械的に分類し,教育支援に役立てることである.
本実験では,そのための具体的な手法として,従来手法である静的解析に基づくクラスタリング手法Asanas Clusterと,近年急速に発展するLLMを用いた分類手法の2つを取り上げ,それぞれの分類精度および特性を比較検証する.具体的に,同一の誤答データセットに対して両手法を適用し,どちらの手法がより高精度に誤答パターンを分類できるかを定量的に評価する.この比較を通じて,誤答コードの自動分類システムを構築する上で,どちらのアプローチがより実用的かつ有効であるかを明らかにすることを目的とする.

\section{実験環境}
本実験は,以下のハードウェアおよびソフトウェア環境下で実施した.
実験の再現性を担保するため,詳細なバージョン情報を記載する.

\subsection{ハードウェア・OS構成}
\begin{itemize}
    \item \textbf{OS}: Windows 11
    \item \textbf{実行環境}: WSL2 (Windows Subsystem for Linux 2) - Ubuntu Environment
\end{itemize}

\subsection{ソフトウェア・ライブラリ}
静的解析に基づく特徴抽出,クラスタリング,および評価指標の算出には,プログラミング言語Pythonを用いた.
主要な使用ライブラリとその用途は以下の通りである.

\begin{itemize}
    \item \textbf{Python}: 3.12.3
    \item \textbf{PyJoern}: ソースコードの静的解析エンジン,CFGおよびDFGの生成に使用.
    \item \textbf{NetworkX}: グラフ構造の解析.循環的複雑度やパス数の算出に使用.
    \item \textbf{scikit-learn}: K-meansクラスタリングの実装,および評価指標（適合率,再現率,F値）の計算に使用.
    \item \textbf{SciPy}: ハンガリアンアルゴリズムの実装.クラスタリング結果と正解ラベルの最適マッチングに使用.
    \item \textbf{NumPy / Pandas}: 数値計算およびデータ処理に使用.
\end{itemize}

また,比較対象となる大規模言語モデルを用いた分類には,OpenAI社が提供するAPIを使用した.

\begin{itemize}
    \item \textbf{使用モデル}: GPT-4o
\end{itemize}

\section{対象データ}
本実験では,オンラインジャッジシステム「AtCoder」上で公開されている問題セット「競プロ典型90問」を対象とした.
この問題セットは,競技プログラミングにおいて頻出するアルゴリズムや実装テクニックを網羅しており,誤答パターンの分析に適すると考えられる.

\subsection{選定問題とデータ規模}
「競プロ典型90問」の中から, 難易度★2に設定されている問題計10問を選定した.
各問題について, 判定結果が「WA (Wrong Answer)」または「TLE (Time Limit Exceeded)」となった提出コードを収集した. データの収集にあたっては, 1つの問題につき100件の誤答コードを抽出した. この際, コーディングスタイルの多様性を確保するため, 同一ユーザーによる提出は重複して取得せず, 100名の異なるユーザーによるソースコードを対象とした.

その結果, 本実験では10種類の問題それぞれについて100件ずつ, 合計10セットの独立したデータ群を使用する.本研究における分析および評価は, これら10セットのデータ群に対して個別に実施するものであり, 異なる問題のデータを混合して扱うことはない.

また, 各データ群は「評価用正解データ」兼「実験用入力データ」として利用する.具体的に, 後述する手順で全データに対して手動で分類ラベルを付与し, 実験時にはこのラベルを隠蔽した状態で各手法に入力する.最終的に, 各手法が出力した分類結果を正解ラベルと照合することで, 分類精度の定量的評価を行う.

\subsection{データのフィルタリングと選定基準}
収集した誤答コードの中には,本研究が目的とする「アルゴリズムや論理の誤り」の分析に適さないデータが含まれている可能性があるため,以下の基準に基づきフィルタリングを行った.

\begin{enumerate}

    \item \textbf{デバッグ出力によるWAの除外}: AtCoderのジャッジシステムでは, 解答と無関係な標準出力が含まれる場合, たとえ計算ロジックが正しくても「WA」と判定される. 本研究の目的はアルゴリズムや論理の誤りを分析することであるため, このような「ロジックは正しいがデバッグ出力の消し忘れによってWAとなったコード」はノイズと見なし, 収集段階で除外した.
  
    \item \textbf{出力形式ミスの除外}:
    アルゴリズムや解法自体は正しいものの,空白区切りで出力すべきリストを,Pythonのリスト形式のまま出力するなど出力形式の不備によってWAとなっているコードは,本研究の分析対象である論理的な誤答ではないため排除した.

    \item \textbf{コンパイル可能性}:
    構文エラーで実行不可能なコードは対象外とし,コンパイルおよび実行が可能でありながら,論理的な誤りまたは実行時間超過が発生するコードのみを対象とした.

    \item \textbf{コメントの削除}:
    前処理として,コード内のコメント記述をすべて削除した.
    手法1においてはコメントの有無は解析結果に影響しないが,手法2においては,コメント内にアルゴリズムのヒントが含まれていた場合に推論が有利になったり,逆にコメントアウトされたデバッグコードを論理的な誤りとして誤認したりする可能性がある.これらのバイアスを排除し,純粋なコードロジックのみによる公平な比較を行うために適用した.
\end{enumerate}

\subsection{正解ラベルの作成}
収集した誤答コードに対する評価の基準を作成するため,各問題のソースコードを目視で確認し,手動による分類を行った.
具体的な手順として,まず収集したコードに見られる具体的な誤りを洗い出し,それらを誤答の原因や種類に基づいて一般化することで,各問題に対して3〜5個程度の主要な誤答カテゴリを定義した.
各問題において定義した誤答カテゴリの内訳を表\ref{tab:error_categories}に示す.

\begin{longtable}{|l|p{10cm}|}
    \caption{各問題における誤答カテゴリの定義}
    \label{tab:error_categories} \\

    % --- 最初のページのヘッダー ---
    \hline
    \textbf{問題ID} & \textbf{定義した誤答カテゴリ} \\
    \hline
    \endfirsthead

    % --- 2ページ目以降のヘッダー（続きとわかるようにする） ---
    \multicolumn{2}{l}{\footnotesize （前ページの続き）} \\
    \hline
    \textbf{問題ID} & \textbf{定義した誤答カテゴリ} \\
    \hline
    \endhead

    % --- 各ページの終わりのフッター ---
    \hline
    \multicolumn{2}{r}{\footnotesize 次ページへ続く} \\
    \endfoot

    % --- 最終ページの終わりのフッター ---
    \hline
    \endlastfoot

    % --- データ本体 ---
    \textbf{aa} &
    1. ハッシュ衝突による誤り \newline
    2. 二分探索の実装およびロジックの間違い \newline
    3. 出力形式または出力内容の間違い \newline
    4. 名簿管理における操作ミス \newline
    5. 重複チェック処理における条件漏れ \\
    \hline

    \textbf{ag} &
    1. 点灯個数の探索・カウント処理の誤り \newline
    2. 特定条件下の考慮漏れ \\
    \hline

    \textbf{bc} &
    1. 全探索によるTLE \newline
    2. 組み合わせ選択後の計算ロジックの誤り \newline
    3. 組み合わせの作成・選択自体の間違い \newline
    4. 計算以外の制約条件確認ミス \newline
    5. 剰余計算処理の誤り \\
    \hline

    \textbf{bi} &
    1. 出力時のインデックス操作ミス \newline
    2. 山札の操作・管理ミス \\
    \hline

    \textbf{bo} &
    1. $N=0$ 等のコーナーケース処理漏れ \newline
    2. 再帰関数による計算エラー \newline
    3. 出力形式または内容の間違い \newline
    4. $n$進数変換処理の実装ミス \\
    \hline

    \textbf{bz} &
    1. グラフ探索の実装不備によるTLE \newline
    2. 「頂点がちょうど1個」の条件判定ミス \newline
    3. 隣接リスト・配列作成時のミス \\
    \hline

    \textbf{d} &
    1. 出力時のインデックス操作ミス \newline
    2. 累積和の作成ロジックの誤り \newline
    3. 累積和を使用していない \newline
    4. 累積和を使用するが計算方法に誤りがある \\
    \hline

    \textbf{j} &
    1. インデックス以外のクエリ処理ミス \newline
    2. クエリ処理時のインデックス操作ミス \newline
    3. 累積和の作成ロジックの誤り \newline
    4. 累積和を使用していない \newline
    5. 最終的な結果の計算ミス \\
    \hline

    \textbf{v} &
    1. 最大公約数の算出ミス \newline
    2. 浮動小数点演算による誤差 \newline
    3. GCDを使用しない場合の最小回数算出ミス \newline
    4. GCDを使用した場合の最小回数算出ミス \\
    \hline

    \textbf{x} &
    1. 判定条件の記述漏れ \newline
    2. 条件判定ロジックの誤り \newline
    3. 差分計算におけるミス \\

\end{longtable}


\section{グラフ生成の妥当性と基本ブロックの確認}
\label{sec:graph_validation}

第\ref{chap:proposal}章で述べた通り,本研究の手法1ではソースコードから直接CFGを生成し,基本ブロック単位での解析を行っている.
この生成プロセスの妥当性,および先行研究で行われていた収縮処理が本手法の生成プロセスにおいて自動的に達成されていることを確認するため,本実験環境における解析対象のソースコード例をリスト\ref{list:cfg_code}に,それに対応して生成されたCFGを図\ref{fig:cfg_example}に示す.

\begin{lstlisting}[caption={入力ソースコード例}, label={list:cfg_code}, basicstyle=\ttfamily\small, frame=single, language=Python]
def classify_sum(a, b):
    x = a * 10
    y = b + 5
    total = x + y

    if total > 50:
        print("Large")
    else:
        print("Small")
\end{lstlisting}

\begin{figure}[tbp]
    \centering
    % グラフの横幅は見やすさに応じて調整してください
    \includegraphics[width=0.85\textwidth]{src/pyjoern_cfg.png}
    \caption{PyJoernによって生成されたCFG（リスト\ref{list:cfg_code}に対応）}
    \label{fig:cfg_example}
\end{figure}

\vspace{3cm}

リスト\ref{list:cfg_code}は単純な条件分岐を含むソースコードである.
これに対応する図\ref{fig:cfg_example}を確認すると,変数定義である \texttt{x=10}, \texttt{y=20}, \texttt{total=x+y} という一連の連続した命令が,個別のノードに分割されることなく,単一の基本ブロックとして統合されていることがわかる.
また,そのブロックから \texttt{if} 文による条件分岐が正しくエッジとして表現されている.

この結果から,本実験の環境において,先行研究が手動で行っていた「冗長な遷移の収縮」が基本ブロックの構築として内包されていることが確認できる.したがって,生成されたグラフはアルゴリズムの構造的特徴を抽出するために十分な抽象度と妥当性を有すると言える.


\section{実験手順}
本実験では,前節で述べた誤答コード群に対し,静的解析に基づく手法とLLMに基づく手法のそれぞれを適用し,分類性能を検証する.
両手法において,最終的な出力と正解ラベルの照合プロセスが異なるため,以下にそれぞれの手順を詳述する.

\subsection{手法1: Asanas Cluster}
本手法は,ソースコードから抽出した特徴量に基づきK-means法により分類を行い,その結果を正解カテゴリに割り当てるアプローチである.

\subsubsection{1. 特徴量の抽出および前処理}
分類の入力データとしては,前章の表\ref{tab:features}で定義したCFGおよびDFGに基づく計11次元の特徴量ベクトルを用いる.

特にpathsの算出においては,ループや分岐構造を適切に反映させるため,「各ノードを最大2回まで訪問してよい」という制約ルールを設けている.

なお,K-means法は特徴量の値の範囲（スケール）の違いによる影響を受けやすいため,先行研究と同様に,前処理としてすべての特徴量が平均0,分散1となるように標準化を行った上で実験に使用した.


\subsubsection{2. K-meansによるクラスタリング}
標準化されたデータに対し,K-means法を適用して分類を行った.クラスタ数 $K$ は,各問題に対して事前に定義した正解カテゴリ数（2〜5個）と一致するように設定した.
この段階で,各コードは機械的に \texttt{cluster1}, \texttt{cluster2} \dots といったクラスタIDに分類される.


\subsubsection{3. ハンガリアンアルゴリズムによる正解ラベルとの対応付け}
本実験では,K-meansの初期値として各正解カテゴリのセントロイドを与えてクラスタリングを行う.
しかし,クラスタリングの過程で重心位置が更新されるため,最終的に出力されるクラスタIDと正解ラベルの対応関係は必ずしも初期状態と一致するとは限らない.

そこで,分類精度を正しく評価するために,形成された各クラスタと正解カテゴリの最適な対応付けを行う必要がある.本実験では,単純な「貪欲法」ではなく,割り当て問題の最適解を導く「ハンガリアンアルゴリズム」を採用した.
以下に,競合がない理想的なケースと,競合が発生するケースの双方において,両アルゴリズムがどのような挙動を示すかを比較する.

\paragraph{ケース1：競合がない場合} \mbox{}\\
各クラスタの特徴が明確で,特定のカテゴリにデータが集中している理想的な状態を表\ref{tab:greedy_success}に示す.

\begin{table}[t]
  \centering
  \caption{競合がない場合のデータ例}
  \label{tab:greedy_success}
  \begin{tabular}{lcc}
    \toprule
      & \textbf{カテゴリA} & \textbf{カテゴリB} \\
    \midrule
    \textbf{クラスタ0} & \textbf{100} & 10 \\
    \textbf{クラスタ1} & 5 & \textbf{90} \\
    \bottomrule
  \end{tabular}
\end{table}

\vspace{3cm}

\begin{itemize}
    \item 貪欲法では,クラスタ0はA(100)を選択し, クラスタ1はB(90)を選択する. 競合しないため, スムーズに最適解(190件)に到達する.
    \item ハンガリアンアルゴリズムでは,全組み合わせを探索するが, 当然「クラスタ0$\to$A, クラスタ1$\to$B」の組み合わせがコスト最大と判定される.
\end{itemize}
このような単純なケースでは, 両手法の結果は完全に一致する.
つまり, ハンガリアンアルゴリズムを用いても貪欲法の利点は損なわれない.

\paragraph{ケース2：競合がある場合} \mbox{}\\
次に, 誤答傾向が似通っており, 複数のクラスタで特定のカテゴリが競合している場合を表\ref{tab:greedy_fail}に示す.


\begin{table}[b]
  \centering
  \caption{競合がある場合のデータ例}
  \label{tab:greedy_fail}
  \begin{tabular}{lcc}
    \toprule
      & \textbf{カテゴリA} & \textbf{カテゴリB} \\
    \midrule
    \textbf{クラスタ0} & \textbf{100} & 99 \\
    \textbf{クラスタ1} & 90 & 5 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{itemize}
    \item 貪欲法では,まずクラスタ0に着目し, 僅差であっても多い方の\textbf{カテゴリA}(100)を確保してしまう. その結果, クラスタ1には本来割り当てるべきA(90)を割り当てられず, 残った\textbf{カテゴリB}(5)が強制的に割り振られる. \\
    $\to$ 総正解数: $100 + 5 = 105$
    
    \item ハンガリアンアルゴリズムでは,「クラスタ0でAを諦めてBを取る($100 \to 99$)」という局所的な損失を受け入れることで, 「クラスタ1でAを取る($5 \to 90$)」という大域的な利益を優先する判断を行う. \\
    $\to$ 総正解数: $99 + 90 = 189$
\end{itemize}

競合が発生した場合, 貪欲法は著しく精度を落とすが, ハンガリアンアルゴリズムは全体最適を保つことができる.


\paragraph{まとめ} \mbox{}\\
以上の比較から, ハンガリアンアルゴリズムは「競合がない場合は貪欲法と同等の結果」を保証しつつ, 「競合がある場合は貪欲法よりも優れた結果」を出すことができる手法であると言える.
本研究の誤答データは性質が近似し競合が発生しやすいため, 安全かつ高精度な評価を行うためにハンガリアンアルゴリズムを採用した.




\subsection{手法2: LLMによる分類手順}
本手法は,LLMにコードと分類基準を提示し,どのカテゴリに該当するかを直接判断させるアプローチで,以下3つの手順により分類を行う.

\begin{enumerate}
    \item \textbf{プロンプトの構築}:
    各問題のソースコードと,前節で定義した「誤答カテゴリのリスト」をプロンプトとして構築した.
    LLMに対し,入力されたコードがリスト内のどのカテゴリに最も適合するかを選択させた.

    \item \textbf{分類結果の出力}:
    LLMは,コードの内容を解析し,その誤答原因に合致すると判断したカテゴリIDを出力する.ここでは,物理的なディレクトリ移動は行わず,各ファイルに対する予測ラベルとして記録した.

    \item \textbf{正解データとの照合}:
    LLMによる予測結果の正当性を検証するため,ファイル名をキーとした正解ラベルの辞書データを作成し,照合を行った.
    具体的には,各ファイルが実際に所属すべき正解カテゴリと,LLMが出力したカテゴリIDが一致するかを確認した.
\end{enumerate}

\section{評価指標}
本実験では,手法1と手法2の分類性能を定量的に比較するため,以下の指標を用いる.
分類結果の妥当性を評価するため,手動で付与した正解カテゴリを「正解」,各手法によって分類された結果を「予測」として定義する.

\subsection{適合率 (Precision)}
適合率は, あるカテゴリとして「予測」されたデータのうち, 実際にそのカテゴリが「正解」であったデータの割合である.
予測結果の中に,どれだけノイズが含まれていないかを示す.

\begin{equation}
  \text{Precision} = \frac{\text{正しく予測されたファイル数}}{\text{当該カテゴリと予測された全ファイル数}}
\end{equation}

この値が1に近いほど,予測結果に含まれるノイズが少ないことを意味する.

\subsection{再現率 (Recall)}
再現率は, あるカテゴリが「正解」であるデータのうち, どれだけ正しく「予測」できたかを表す割合である.
本来検出スべきデータをどれだけ網羅できたかを示す.

\begin{equation}
  \text{Recall} = \frac{\text{正しく予測されたファイル数}}{\text{当該カテゴリが正解である全ファイル数}}
\end{equation}

この値が1に近いほど,取りこぼしが少ないことを意味する.

\subsection{F値 (F1-score)}
適合率と再現率の調和平均である. 精度の高さ（ノイズの少なさ）と網羅性（取りこぼしのなさ）のバランスを表す総合的な指標となる.

\begin{equation}
  \text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

適合率と再現率のどちらか一方が極端に低い場合,F値は大きく低下するため,バランスの取れた分類ができているかを判定するのに適する.
