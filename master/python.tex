\chapter{分類手法の提案}
\label{chap:proposal}

% 本章では,プログラムソースコードからその構造的・意味的な特徴を抽出し,機能的な類似性に基づいて分類を行うための手法について詳述する.本研究では,複数のアプローチを検討するが,本節では先行研究であるAsanas Cluster \cite{Asanas Cluster}のアプローチに基づいた第一の手法について述べる.

本章では, ソースコードからその構造的・意味的な特徴を抽出し, 機能的な類似性に基づいて分類を行うための手法について詳述する. 本研究では, アプローチの異なる2つの手法（以下, 手法1および手法2）を採用し, 両者を比較検証する.

手法1は, 先行研究であるAsanas Cluster \cite{Asanas Cluster}のアプローチに基づき, ソースコードの制御フローやデータフローといった構造的特徴量を抽出し, クラスタリングアルゴリズムを用いる静的解析アプローチである. 対して手法2は, LLMの文脈理解能力を活用し, コードの意味内容に基づいて分類を行う生成AIアプローチである.

これら2つの手法を取り上げる理由は, 明確な数理的特徴に基づく従来の手法と, 近年急速に発展した意味論的解釈に基づく手法を対比させることで, 各アプローチの有効性と限界を明らかにするためである. 以下, 3.1節ではまず手法1の詳細について述べ, 続く節で手法2について説明する.

\section{手法1 : Asanas Clusterによる誤答分類}
\label{sec:method1}

本節では,提案手法の一つである「Asanas Cluster」について説明する.本手法は,ソースコードを静的解析し,その構造的特徴をベクトル化することで,教師なし学習によるクラスタリングを行うものである.
特筆すべき点として,本手法および先行研究は,コードの表層的な構文情報ではなく,アルゴリズムの「実行フロー」と「データの流れ」に着目する点が挙げられる.

\subsection{処理概要}
\label{subsec:processing_flow}

本提案手法の全体的な処理フローを図\ref{fig:processing_flow}に示す.
本システムは,入力されたソースコードに対して,以下4つの工程によりクラスタリング結果を出力する.

\begin{enumerate}
    \item 入力されたソースコードに対し,静的解析ツールを用いてプログラムの構造をグラフとして抽出する.
    \item 生成されたグラフ構造から,分類に有効な11種類の数値特徴量を抽出する.
    \item 抽出された特徴に対し,重要度に応じた重みづけと標準化を行い,数値ベクトルに変換する.
    \item ベクトル化されたデータに対し,インクリメンタルなK-meansアルゴリズムを適用し,類似したアルゴリズム戦略を持つ解答群を同一クラスタに分類する.
\end{enumerate}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{src/asanas_flow.jpg}
    \caption{Asanas Clusterの処理概要図}
    \label{fig:processing_flow}
\end{figure}

\subsection{グラフ生成と解析アプローチ}
\label{subsec:graph_generation}

先行研究であるAsanas Cluster \cite{Asanas Cluster} では,解析基盤としてコードプロパティグラフ (CPG) と呼ばれる統合データ構造を採用する.
CPGはAST,CFG,DFGを包含する詳細なグラフであり,先行研究ではここから評価順序グラフ (EOG) を経てCFGを生成し,さらにデータフロー情報を組み合わせることで特徴量を算出する.

一方,本研究では,分類に必要な特徴量が最終的に「CFGによる構造情報」と「データフローによる依存関係」の2点に集約されることに着目した.
そのため,CPGという包括的なグラフ構造を明示的に生成する中間工程は実装の複雑化を招くため省略し,ソースコードから直接的にCFGの構築およびデータフロー解析を行うアプローチを採用する.これにより,先行研究と同等の情報をより軽量な処理で抽出することを目的とする.

具体的な解析対象は以下の2点である.

% \subsubsection{CFGの構築}
\paragraph{CFGの構築} \mbox{}\\
プログラムの実行順序を表現するグラフである.
先行研究では,詳細なノード粒度を持つCPGからCFGを生成するため,分岐や合流を持たない連続した命令を収縮させてブロック化する後処理を必要としていた.

これに対し本手法では,基本ブロックを単位とする標準的なCFG構築手法を採用する.基本ブロックとは,内部に分岐や合流を含まない一連の命令列を指すため,グラフ生成を行った段階で既に冗長な遷移は集約されている.したがって,先行研究で行われている収縮処理は,本手法の生成プロセスにおいては自動的に達成されるため,明示的な後処理としては不要となる.これにより,アルゴリズムの骨格（分岐,ループなど）を直接的かつ効率的に抽出する.なお,本手法によって生成されるグラフの妥当性および基本ブロックによる集約の確認については,第\ref{sec:graph_validation}節の実験設定にて実例を用いて詳述する.

% \subsubsection{データフロー解析}
\paragraph{データフロー解析} \mbox{}\\
変数間の定義と使用のつながりを追跡する解析である.
CFGだけでは捉えきれない「値の流れ」を解析することで,制御構造が類似していてもデータの処理手順が異なるアルゴリズムの識別を可能にする.

\subsection{特徴量の定義とベクトル化}
\label{subsec:feature_definition}

グラフ構造（CFGおよびDFG）同士の類似度を直接算出するグラフ編集距離等の手法は,計算コストが極めて高い.そこで本手法では,先行研究 \cite{Asanas Cluster}のアプローチに倣い,グラフ構造から抽出したスカラー値による特徴ベクトルを用いる手法を採用する.

具体的には,先行研究で有効性が示されている表\ref{tab:features}の定義に従い,CFGからプログラムの複雑さを,データフロー解析の結果から変数の利用特性を抽出し,合計11次元の特徴ベクトルを構成する.

\begin{table}[h]
    \centering
    \caption{Asanas Clusterにおける特徴量一覧と重みづけ \cite{Asanas Cluster}}
    \label{tab:features}
    \begin{tabular}{llcc}
        \toprule
        \textbf{特徴量} & \textbf{詳細} & \textbf{グラフ} & \textbf{重み} \\
        \midrule
        connected\_components & 制御フローグラフ内の連結成分数 & CFG & 1.0 \\
        loop\_statements & ループ文(for, while等)の数 & CFG & 1.0 \\
        conditional\_statements & 条件分岐文(if等)の数 & CFG & 1.0 \\
        cycles & グラフ内のサイクルの数 & CFG & 1.0 \\
        paths & グラフ内の異なるパスの数 & CFG & 1.0 \\
        cyclomatic\_complexity & サイクロマティック複雑度 & CFG & 1.0 \\
        \midrule
        variable\_count & 使用されている変数の総数 & DFG & 0.6 \\
        total\_reads & 変数読み取り操作の総数 & DFG & 0.1 \\
        total\_writes & 変数書き込み操作の総数 & DFG & 0.1 \\
        max\_reads & 単一変数に対する最大読み取り数 & DFG & 0.1 \\
        max\_writes & 単一変数に対する最大書き込み数 & DFG & 0.1 \\
        \bottomrule
    \end{tabular}
\end{table}

\paragraph{特徴量の選定意図と重みづけ} \mbox{}\\
各特徴量に対する重みづけについても,先行研究における設定を踏襲する.
先行研究では,アルゴリズムの戦略においては命令の実行順序が最も支配的であるという知見に基づき,CFG由来の特徴量に対してそれぞれ $1.0$ の重みを付与する.一方で,データフロー情報は補助的な特徴と位置づけられ,合計でCFG特徴量1つ分となるように重みが分散されている.これは,変数の個数や操作回数がアルゴリズムの本質よりも実装スタイルに依存しやすい傾向を考慮した設計である.

\paragraph{特徴量の前処理と選定} \mbox{}\\
\label{subsec:preprocessing}
抽出された11次元の特徴ベクトルに対し,クラスタリング精度を高めるための前処理を行う.このプロセスについても,基本的に先行研究の手順に準拠する.

\paragraph{特徴量の選定} \mbox{}\\
特徴量間の冗長性を排除するため,データセットを用いて各特徴量ペアのピアソンの相関係数を算出する.先行研究で採用されている基準と同様に,相関係数が $0.9$ を超えるペアが存在する場合,投票形式により冗長な特徴量を削除する判定を行う（なお,本実験データセットにおいては先行研究のデータを参考にするため該当ペアは存在しなかった）.

\paragraph{インクリメンタルな正規化} \mbox{}\\
各特徴量のスケールを統一するため,平均0,分散1への正規化（標準化）を行う.本システムは提出物が逐次入力されるオンライン処理を想定するため,全データの統計量を事前に固定するのではなく,各特徴量について実行平均と実行分散を更新しながら正規化を行う実装とする.

\subsection{クラスタリングアルゴリズム}
\label{subsec:clustering_algorithm}

前節で定義した\textbf{11次元の特徴量ベクトル}を入力とし,K-means法を用いたクラスタリングを行う.
本研究では,Paivaらによる先行研究 \cite{Asanas Cluster}において提案されたインクリメンタルK-meansアルゴリズムを全面的に採用する.
なお,本手法におけるクラスタリング計算は11次元の特徴量空間上で直接行われるものであり,可視化のために用いられる2次元平面上の操作ではない.

\subsubsection{採用したアルゴリズムと処理フロー}

本手法で用いるクラスタリング処理の擬似コードを Algorithm \ref{alg:clustering} に示す.これは先行研究 \cite{Asanas Cluster}で定義された処理フローを再現したものである.

\begin{algorithm}[t]
\caption{インクリメンタルK-meansアルゴリズム (文献\cite{Asanas Cluster}より採用)}
\label{alg:clustering}
\begin{algorithmic}[1]
\Require $k$: クラスタ数 ($2 \le k \le 16$)
\Require $C$: ランダムに初期化された$k$個のセントロイド集合（各セントロイドは11次元ベクトル）
\Require $N$: 各クラスタの要素数配列（0で初期化）
\Procedure{ProcessSubmission}{$S$}
    \State \Comment{$S$ は新規提出コードから抽出された11次元特徴量ベクトル}
    \State $min\_dist \gets \infty$
    \State $min\_c \gets \text{null}$

    \State \Comment{1. 11次元空間におけるユークリッド距離を用いて最近傍セントロイドを探索}
    \For{each centroid $c \in C$}
        \State $d \gets \text{EuclideanDistance}(c, S)$
        \If{$d < min\_dist$}
            \State $min\_dist \gets d$
            \State $min\_c \gets c$
        \EndIf
    \EndFor

    \State \Comment{2. クラスタ統計情報を更新}
    \State $N[min\_c] \gets N[min\_c] + 1$

    \State \Comment{3. セントロイド位置を更新 (オンライン更新)}
    \If{$S$ is Correct}
        \State $\eta \gets 1 / N[min\_c]$ \Comment{学習率の算出}
        \State $min\_c \gets min\_c + \eta \times (S - min\_c)$ \Comment{ベクトル演算によりセントロイドを $S$ の方向へ移動}
    \EndIf

    % \State \Return $min\_c$
\EndProcedure
\end{algorithmic}
\end{algorithm}

% \vspace{15mm}

このアルゴリズムは,新規の提出データ $S$ がシステムに入力されるたびに実行され,以下の3つのステップで処理が進む.

\begin{enumerate}
    \item 事前に$k$個のセントロイド $C$ をランダムに初期化しておく.新規入力 $S$ に対し,\textbf{11次元の特徴量空間上での}ユークリッド距離を用いて最も近いセントロイド $min\_c$ を特定する.
    \item 特定されたクラスタに属する要素数 $N$ をインクリメントする.
    \item 入力 $S$ が正解コードである場合のみ,モデルの学習を行う.具体的には,そのクラスタの要素数に応じた学習率 $\eta = 1/N$ を算出し,セントロイドmin\_cを $S$ の方向へ $\eta$ の割合だけ移動させる.
\end{enumerate}

\subsubsection{アルゴリズムおよびパラメータの選定理由}
本研究において上記のアルゴリズムおよび設定を採用した理由は,先行研究における以下の検証結果に基づく.

\paragraph{インクリメンタル手法の採用理由} \mbox{}\\
通常のK-means法を本システムのように学生が順次解答を提出する環境に適用した場合,新たなデータが追加されるたびに全データを用いたモデルの再学習が必要となる.これでは計算コストが肥大化し,学生への即時フィードバックに必要な応答速度を維持できないため適さない. これに対し先行研究では,データ到着ごとに重心を更新するオンライン学習アプローチによって,大規模な再計算を行うことなく,低コストかつリアルタイムにモデルを最新状態に維持できることが示されているため,これを採用した \cite{Asanas Cluster}.

\paragraph{ユークリッド距離の選定理由} \mbox{}\\
最近傍探索における距離尺度としてユークリッド距離を選定した理由は,アルゴリズム戦略の分離精度にある.先行研究では,クラスタリングの精度評価として誤分類の度合いを示すエラー指標が用いられている.その結果,マンハッタン距離では0.3,コサイン距離では0.25であったのに対し,ユークリッド距離では0となり,誤分類が発生しないことが報告されている.本研究においても高い分類精度を確保するため,この結果に基づき\textbf{多次元特徴量空間における}ユークリッド距離を採用する \cite{Asanas Cluster}.

\paragraph{クラスタ数 $k$ の設定} \mbox{}\\
クラスタ数 $k$ の上限を16とするのは,一般的なプログラミング課題において想定される正解アルゴリズム戦略の種類が16を超えることは稀であるという先行研究の知見に基づいている \cite{Asanas Cluster}.


\subsection{誤答分類への適用と対応点}
Asanas　Cluster \cite{Asanas Cluster}は, 正解コードの構造的特徴を抽出してアルゴリズム戦略ごとに分類することを目的としていた. これに対し本研究では, 同一の手法を「誤答コードの分類」に適用する.
本手法が誤答のパターン分類にも有効であると考える理由は, 抽出される11次元の特徴量がプログラムの「構造」と「データの流れ」を定量化しているためである.

具体的に, 誤答コードにおけるバグや実装ミスは特徴量ベクトル上の差異として現れると仮定できる.
例えば, ループ条件の誤りや分岐の欠落といった論理的なバグはCFGの形状を変化させるため, 特徴量である \texttt{loop\_statements}や \texttt{cyclomatic\_complexity}の値が, 正解コードや他の種類の誤答とは異なる挙動を示すと考えられる.
また, 変数の初期化忘れや誤った代入といったデータ操作に関するバグはDFGにおける依存関係を変化させるため, \texttt{total\_reads}や\texttt{max\_writes}といったデータフロー特徴量の変動として捉えることが可能である.

したがって, 本研究では先行研究における「アルゴリズム戦略の差異によるクラスタ形成」という概念を, 「誤答原因（バグの種類）の差異によるクラスタ形成」に対応させて適用する. これにより, 構文的な違いに左右されず, 構造的・意味的な誤りの傾向に基づいて誤答を分類可能であるかを検証する.

\section{手法2 : LLMによる誤答分類}
本節では,もう一つの提案手法のとなるLLMを用いた誤答分類システムについて\\詳述する.

\subsection{分類のアプローチ}
本手法では,ソースコードの意味理解において優れた性能を示すLLMに対し,「問題文」「誤答コード」「分類カテゴリ」の3要素を入力として与え,そのコードが定義されたカテゴリのいずれに該当するかを判定させる.
静的解析や単純なパターンマッチングなど従来の手法とは異なり,LLMはコードの文脈や意図を深く理解できるため,論理的な誤りや複雑なバグに対しても高精度な分類が期待できる.

\subsection{モデル選定}
本研究では,誤答分類を行う基盤モデルとして,OpenAI社が提供するGPT-4oを採用した.
2025年現在,より推論能力に特化した OpenAI o1 や,コーディング生成能力に優れた Claude 3.5 Sonnet などのモデルが存在するが,本研究の目的である「教育的フィードバックのための誤答分類」においては,以下の3点の技術的・実用的観点から GPT-4o が最適であると判断した.

\begin{enumerate}
    \item \textbf{指示従順性と出力形式の安定性:}
    本手法のプロンプトでは,後段のシステムで回答を機械的に処理するため,「間違いの説明」の後に「カテゴリ番号」のみを出力するという特定のフォーマットを遵守する必要がある.
    GPT-4o は複雑な指示に対する従順性が極めて高く,従来のモデルで頻発した「余計な会話文の混入」や「出力順序の逸脱」といったフォーマット違反が少ない\cite{openai_structured_2024}.これにより,正規表現等を用いた分類ラベルの抽出処理を安定して行うことが可能となり,システム化に適する.

    \item \textbf{分類タスクにおける適合率の高さ:}
    教育現場におけるフィードバックでは,正解を誤って不正解と判定する「誤検知」が学習者の混乱を招くため,極力避ける必要がある.既存のベンチマーク評価によると,GPT-4o は分類タスクにおいて Claude 3.5 Sonnet と比較して高い適合率（Precision 86.2\%）を示す傾向が報告されている \cite{vellum_2025}.生成能力（コードを書く力）においては他モデルが優位な場合もあるが,誤りの識別能力（コードを読む力）においては GPT-4o が本タスクに対しより保守的かつ適切な特性を持つ.

    \item \textbf{推論速度とコストのスケーラビリティ:}
    推論特化型モデル（OpenAI o1 等）は高い論理性能を持つ反面,応答に数十秒の時間を要するため,将来的なリアルタイム・フィードバック・システムへの応用には不向きである.
    GPT-4o は旧世代モデルと比較して約2倍の生成速度を持ちながら,十分な論理推論能力（MATHベンチマーク 76.6\%）を維持する \cite{sentisight_2025}.また,同一アーキテクチャの軽量モデル（GPT-4o mini）への蒸留が可能であり,将来的な大規模展開におけるコストパフォーマンスの向上が見込める.
\end{enumerate}

\subsection{プロンプト設計}
LLMの性能を最大限に引き出し,かつ揺らぎの少ない出力を得るため,プロンプトの設計には細心の注意を払った.
実際に使用するプロンプトの構成をリスト\ref{list:prompt_design}に示す.

% \begin{figure}[t]
%     \centering
%     % widthで行幅いっぱい,colback=whiteで背景白,colframe=blackで枠黒
%     % boxrule=0.5ptで細い枠線,sharp cornersで角を直角に
%     \begin{tcolorbox}[width=0.95\textwidth, colback=white, colframe=black, boxrule=0.5pt, sharp corners, fontupper=\ttfamily\small]
% このコードの間違いを教えてください.\\
% 最後に以下のカテゴリのどれに当たるか数字のみ出力してください.\\
% 間違いの説明とカテゴリのみ出力してください.\\

% 【問題文（必要最低限の情報）】\\
% (ここに問題文を記述)\\

% 【カテゴリ】\\
% 1. [カテゴリ1]\\
% 2. [カテゴリ2]\\
% ...\\
% n. [カテゴリn]\\

% 【コード】\\
% (ここに誤答コードを記述)\\
%     \end{tcolorbox}
%     \caption{提案手法2で使用するプロンプト構成}
%     \label{fig:prompt_design}
% \end{figure}

\begin{lstlisting}[
    caption={提案手法2で使用するプロンプト構成},
    label={list:prompt_design},
    language={},
    escapechar=|,        % |で囲った部分を通常のLaTeXとして処理する設定
    basicstyle=\ttfamily\small,
    frame=single         % 枠線が必要な場合
]
|このコードの間違いを教えてください.|
|最後に以下のカテゴリのどれに当たるか数字のみ出力してください.|
|間違いの説明とカテゴリのみ出力してください.|

|【問題文（必要最低限の情報）】|
|(ここに問題文を記述)|

|【カテゴリ】|
|1. [カテゴリ1]|
|2. [カテゴリ2]|
|...|
|n. [カテゴリn]|

|【コード】|
|(ここに誤答コードを記述)|
\end{lstlisting}

プロンプト設計においては,以下の工夫を取り入れた.

\begin{itemize}
    \item \textbf{入力情報の最適化}:問題文に含まれるストーリー要素などのノイズを除去し, 制約条件や入出力形式のみを抽出した. これにより, LLMがアルゴリズムの本質的理解や論理構造の解析に集中できるよう入力を最適化する.

    \item \textbf{Chain-of-Thoughtによる推論精度の向上}:カテゴリ番号の出力に先立ち「誤りの説明」を生成させることで, Chain-of-Thought（思考の連鎖）効果を導入した. まず誤りを言語化させるプロセスを経ることで, 推論の根拠を明確にし, 分類精度の向上を図っている.

    \item \textbf{出力形式の厳格化}:最終的な出力を所定のフォーマットに限定することで,後段のシステムにおける機械的なパースを容易にし,安定したシステム動作を担保する.
\end{itemize}

