\chapter{結果と考察}
\section{実験結果}
前節の実験設定に基づき,手法1および手法2を用いて分類を行い,各評価指標を算出した結果を表\ref{tab:simple_grid},\ref{tab:average_scores}に示す.

{ % スコープを限定するための括弧開始
\small % 文字サイズを小さくする (または \footnotesize)
\renewcommand{\arraystretch}{1.1} % 行間を少し詰める (通常は1.0)
\begin{longtable}{|c|l|c|c|}
\caption{各問題カテゴリにおける評価指標} \label{tab:simple_grid} \\

% --- 最初のページのヘッダー ---
\hline
\textbf{問題} & \textbf{カテゴリ} & \textbf{手法1} & \textbf{手法2} \\
\hline
\endfirsthead

% --- 2ページ目以降のヘッダー（続きとわかるようにする） ---
% \multicolumn{2}{l}{\footnotesize （前ページの続き）} \\
\hline
\textbf{問題} & \textbf{カテゴリ} & \textbf{手法1} & \textbf{手法2} \\
\hline
\endhead

% --- 各ページの終わりのフッター ---
\hline
\multicolumn{2}{r}{\footnotesize (次ページへ続く)} \\
\endfoot

% --- 最終ページの終わりのフッター ---
\hline
\endlastfoot



% --- AA (5行) --- やっぱ同じ構造のコードは分類ムズイ
\multirow{5}{*}{\textbf{AA}}
 & カテゴリ1 & 0.40 & 0.91 \\ \cline{2-4}
 & カテゴリ2 & 0.50 & 0.57 \\ \cline{2-4}
 & カテゴリ3 & 0.36 & 0.77 \\ \cline{2-4}
 & カテゴリ4 & 0.00 & 0.35 \\ \cline{2-4}
 & カテゴリ5 & 0.53 & 0.62 \\ \hline

% --- AG (2行) ---
\multirow{2}{*}{\textbf{AG}}
 & カテゴリ1 & 0.77 & 0.57 \\ \cline{2-4}
 & カテゴリ2 & 0.97 & 0.98 \\ \hline

% --- BC (5行) ---
\multirow{5}{*}{\textbf{BC}}
 & カテゴリ1 & 0.00& 0.33 \\ \cline{2-4}
 & カテゴリ2 & 0.46 & 0.26 \\ \cline{2-4}
 & カテゴリ3 & 0.17 & 0.27 \\ \cline{2-4}
 & カテゴリ4 & 0.44 & 0.67 \\ \cline{2-4}
 & カテゴリ5 & 0.77 & 0.67 \\ \hline

% --- BI (2行) ---
\multirow{2}{*}{\textbf{BI}}
 & カテゴリ1 & 0.82 & 0.65 \\ \cline{2-4}
 & カテゴリ2 & 0.00 & 0.83 \\ \hline

% --- BO (4行) ---
\multirow{4}{*}{\textbf{BO}}
 & カテゴリ1 & 0.67 & 0.82 \\ \cline{2-4}
 & カテゴリ2 & 0.10 & 0.36 \\ \cline{2-4}
 & カテゴリ3 & 0.00 & 0.11 \\ \cline{2-4}
 & カテゴリ4 & 0.13 & 0.00 \\ \hline

% --- BZ (3行) ---
\multirow{3}{*}{\textbf{BZ}}
 & カテゴリ1 & 0.50 & 0.68 \\ \cline{2-4}
 & カテゴリ2 & 0.69 & 0.00 \\ \cline{2-4}
 & カテゴリ3 & 0.53 & 0.40 \\ \hline

% --- D (4行) ---
\multirow{4}{*}{\textbf{D}}
 & カテゴリ1 & 0.00 & 0.33 \\ \cline{2-4}
 & カテゴリ2 & 0.29 & 0.22 \\ \cline{2-4}
 & カテゴリ3 & 0.48 & 0.44 \\ \cline{2-4}
 & カテゴリ4 & 0.40 & 0.50 \\ \hline

% --- J (5行) ---
\multirow{5}{*}{\textbf{J}}
 & カテゴリ1 & 0.22 & 0.67 \\ \cline{2-4}
 & カテゴリ2 & 0.66 & 0.87 \\ \cline{2-4}
 & カテゴリ3 & 0.38 & 0.83 \\ \cline{2-4}
 & カテゴリ4 & 0.31 & 0.94 \\ \cline{2-4}
 & カテゴリ5 & 0.00 & 0.67 \\ \hline

% --- V (4行) ---
\multirow{4}{*}{\textbf{V}}
 & カテゴリ1 & 0.33 & 0.53 \\ \cline{2-4}
 & カテゴリ2 & 0.39 & 0.58 \\ \cline{2-4}
 & カテゴリ3 & 0.17 & 0.66 \\ \cline{2-4}
 & カテゴリ4 & 0.63 & 0.83 \\ \hline

% --- X (3行) ---
\multirow{3}{*}{\textbf{X}}
 & カテゴリ1 & 0.63 & 0.83 \\ \cline{2-4}
 & カテゴリ2 & 0.00 & 0.71 \\ \cline{2-4}
 & カテゴリ3 & 0.42 & 0.77 \\ \hline

\end{longtable}
}

\begin{table}[b]
  \centering
  \caption{問題ごとの平均スコアおよび全体平均}
  \label{tab:average_scores}
  \begin{tabular}{|l|c|c|}
    \toprule
    \textbf{問題ID} & \textbf{手法1} & \textbf{手法2} \\
    \midrule
    \textbf{AA} & 0.36 & \textbf{0.64} \\
    \textbf{AG} & \textbf{0.87} & 0.78 \\
    \textbf{BC} & 0.37 & \textbf{0.44} \\
    \textbf{BI} & 0.41 & \textbf{0.74} \\
    \textbf{BO} & 0.23 & \textbf{0.32} \\
    \textbf{BZ} & \textbf{0.57} & 0.36 \\
    \textbf{D}  & 0.29 & \textbf{0.37} \\
    \textbf{J}  & 0.31 & \textbf{0.80} \\
    \textbf{V}  & 0.38 & \textbf{0.65} \\
    \textbf{X}  & 0.35 & \textbf{0.77} \\
    \midrule
    \textbf{全体平均} & 0.38 & \textbf{0.57} \\
    \bottomrule
  \end{tabular}
\end{table}

表\ref{tab:simple_grid},\ref{tab:average_scores}の結果を見ると,多くの問題において手法1と比較して,手法2の方が高いスコアを示す傾向が見られた.
特に問題JやXにおいては,手法2が全体を通して安定して高い分類精度を記録する.その一方で,問題AGなど一部のケースにおいては,手法1のスコアが手法2を上回る,あるいは同等の高い値を示す.

\section{考察}
実験結果のスコアをもとに手法1と手法2のそれぞれスコアが高く,精度の高い分類ができた要因とスコアが低く精度の低い分類ができた要因またはLLMの実験結果で注意深い結果を確認できたので考察していく.
なお,本研究では誤答コードの性質を解析対象とするため,提出者のプライバシー保護および不利益の防止を目的として,すべてのデータは匿名化処理を行い,個人が特定されない形で使用する.

\subsection{手法1による分類が有効であった事例と考察}
\label{subsec:case_study_ag}

手法1において,特に高い精度で誤答コードの分類が行えた事例として,問題AG（033 - Not Too Bright \cite{typical90_ag}）を取り上げる.

\subsubsection{問題概要と分類結果}
問題AGは,$H \times W$ のグリッド上にLEDを配置する際,「任意の $2 \times 2$ の領域内に2つ以上のLEDが点灯していてはならない」という制約下で,点灯可能なLEDの最大個数を求める問題である.

本問題に対する手法1の適用結果を図\ref{fig:asanas_pca_result}に示す.
図の左側は手動で分類した正解ラベルに基づく分布, 右側は手法1によって自動分類された結果である.
この図は,抽出された11次元の特徴量ベクトルを主成分分析（PCA）を用いて2次元に圧縮・可視化したものであり,点同士の空間的な距離が近いほど,コードの構造的特徴が類似していることを意味する.

\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\textwidth]{src/ag_tea.png}
    \caption{問題AGにおける特徴量分布の可視化（左：正解ラベルに基づく分布, 右：手法1による分類結果）}
    \label{fig:asanas_pca_result}
\end{figure}


\newpage

左図（正解分布）を確認すると,データは空間上で明確に2つの集団に分離していることがわかる.
これに対応して,右図（手法1）においても,その分布形状をなぞるように2つのクラスタが形成されており,手法1がコードの構造的な差異を正しく検知し,分離に成功していることが視覚的に確認できる.

解析の結果,この空間的な分離は,表\ref{tab:error_categories}で定義した以下の2つの誤答カテゴリの違いを反映している.

\begin{enumerate}
    \item \textbf{点灯個数の探索・カウント処理の誤り}: 動的計画法（DP）や全探索を用いて配置をシミュレートしようとし,実行時間制限超過（TLE）となるパターン.
    \item \textbf{特定条件下の考慮漏れ}: 数学的考察により計算式を導出したが,特定の条件（$H=1$ または $W=1$）を考慮できていないパターン.
\end{enumerate}


% \newpage

\subsubsection{具体的な誤答コードの比較}
表\ref{tab:error_categories}で定義されたカテゴリ間で,コード構造にどのような差異があるかを具体的に確認する.

ソースコード\ref{list:ag_tle}は,カテゴリ「点灯個数の探索・カウント処理の誤り」に分類された典型的なコードである.
このコードでは,2次元配列 dp を用意し,2重ループを用いてグリッド全体を探索する.
この手法は,H,Wの問題の制約に対して計算量が過大となり,TLEを引き起こす.
構造的特徴として,ネストされたループ構造や,配列への頻繁なアクセスが挙げられる.

\begin{lstlisting}[caption={カテゴリ1：点灯個数の探索・カウント処理の誤り}, label={list:ag_tle}, language=Python]
def notTooBright(H: int, W: int) -> int:
    dp = [[False] * (W + 1) for _ in range(H + 1)]
    total = 0
    for r in range(1, H + 1):
        for c in range(1, W + 1):
            if not dp[r - 1][c - 1] and not dp[r - 1][c] and not dp[r][c - 1]:
                dp[r][c] = True
                total += 1
    return total

def main():
    H, W = map(int, input().split())
    print(notTooBright(H, W))

if __name__ == "__main__":
    main()
\end{lstlisting}

一方,ソースコード\ref{list:ag_wa}は,カテゴリ「特定条件下の考慮漏れ」に分類されたコードである.
ここではループ処理を用いず,数式によって直接解を算出する.
この計算式自体は正しいが,行または列が1の場合（$H=1$ または $W=1$）にはすべてのマスに配置可能であるというコーナーケースの考慮が漏れており,WAとなる.
このカテゴリのコードは,カテゴリ1とは対照的に,制御構造が極めて単純であり,演算処理が支配的であるという特徴を持つ.

\begin{lstlisting}[caption={カテゴリ2：特定条件下の考慮漏れ}, label={list:ag_wa}, language=Python]
h, w = map(int, input().split())

print(((h+1)//2) * ((w+1)//2))
\end{lstlisting}

上記2つのコード例から明らかなように,この問題における2つの誤答カテゴリは,コードの構造に決定的な差異がある.
表\ref{tab:error_categories}の定義におけるカテゴリ1は「多重ループと条件分岐」を主体とするのに対し,カテゴリ2は「単純な算術演算」のみで構成されている.
手法1で用いている静的解析特徴量は,このような構造的な違いを鋭敏に捉えることができる.
その結果,特徴量空間において両者が大きく離れた位置に分布し,K-means法によるクラスタリングが高精度に機能したと考えられる.
したがって,誤答の種類によってアルゴリズムの選択や実装方針が根本的に異なる場合,本手法であるAsanas Clusterアプローチは極めて有効である.

ただし,本手法は「コードの構造的な類似性」に基づいて分類を行っているため,カテゴリ2のように「数式は合っているが,特定の条件分岐が抜けている」といった,行レベルでの具体的なバグ箇所の特定までは行えていない点には留意が必要である.



\subsection{手法1による分類が困難であった事例と考察}
\label{subsec:case_study_010}
前節で述べた問題AGのような成功例がある一方で,多くの問題では明確な分離が困難であった.
その代表例として,「競プロ典型90問 - 010 Score Sum Queries \cite{typical90_j}」（以下,問題J）を取り上げ,静的解析ベースの手法の限界について考察する.

\subsubsection{問題概要と分類結果}
問題Jは,$N$ 人の生徒がクラス1またはクラス2に所属しており,与えられた $Q$ 個のクエリ（範囲 $[L_i, R_i]$）に対して,各クラスの点数合計を回答する問題である.
制約上,単純なループによる集計では間に合わず,累積和を用いた $O(1)$ または $O(\log N)$ でのクエリ処理が必須となる.

本問題に対する手法1の適用結果を図\ref{fig:010_pca_result}に示す.
図の左側は正解ラベルに基づく分布, 右側は手法1による分類結果である.
目視による定性評価では,本問題の誤答コードは主に表\ref{tab:error_categories}に示す5つのカテゴリに分類された.

\begin{enumerate}
    \item \textbf{インデックス以外のクエリ処理ミス}: 入力受け取りまでは行っているが,クエリごとの計算ロジックが破綻する,あるいは記述されていない.
    \item \textbf{クエリ処理時のインデックス操作ミス}: 累積和は作成できているが,区間計算時に $L$ と $R$ を逆にする等のミスがある.
    \item \textbf{累積和の作成ロジックの誤り}: 累積和作成時のループ範囲やインデックス参照にズレがある.
    \item \textbf{累積和を使用していない}: 累積和を使わず,クエリごとに配列をスライスして合計を計算する（TLE）.
    \item \textbf{最終的な結果の計算ミス}: 累積和の値は取得できているが,その後の差分計算等のロジックが誤っている.
\end{enumerate}

\newpage

しかし, 図\ref{fig:010_pca_result}の左図（正解分布）を確認すると, 問題AGとは対照的に, 異なる誤答カテゴリ（特にカテゴリ2, 3, 4など）に対応する点が空間上で分離せず, 同一の領域（主に左下）に混在していることがわかる.
これは, これらの誤答がいずれも「配列確保とループ処理」という類似した構造を持っており, 静的解析では論理的な微差を特徴量として識別できなかったためである.
その結果, 右図（手法1）に示すように, 手法1は大半のデータを単一のクラスタ（C0）に統合してしまい, 有効な分類を行うことができなかった.

\begin{figure}[tbp]
    \centering
    \includegraphics[width=1.0\textwidth]{src/j_tea.png}
    \caption{問題Jにおける特徴量空間のPCA可視化結果（左：正解パターンの混在, 右：手法1による分類結果）}
    \label{fig:010_pca_result}
\end{figure}



\subsubsection{具体的な誤答コードの比較}
なぜ分類が困難であったかを確認するため,混同が生じた主な2つのグループについてコード構造の観点から比較を行う.

\paragraph{グループ1：アルゴリズム構造の類似（カテゴリ2, 3, 5）}\mbox{}\\
一つ目の混同パターンは,カテゴリ2（インデックス操作ミス）,カテゴリ3（累積和作成ロジック誤り）,カテゴリ5（計算ミス）が同一クラスタに含まれるケースである.
これらは「配列の確保」「前処理のループ」「クエリ処理のループ」という共通の構成を持っているため,静的解析特徴量が極めて類似する.

以下の3つのソースコード（\ref{list:010_index_error}, \ref{list:010_cumsum_error}, \ref{list:010_calc_error}）は,それぞれ「累積和作成時」「クエリ処理時」「最終計算時」とバグの発生箇所が異なる.
しかし,静的解析ではファイル全体の特徴量として集約されるため,「どこで間違えているか」という局所的な情報の差異は無視され,同一視されてしまう.

\newpage

\begin{lstlisting}[caption={カテゴリ2：クエリ処理時のインデックス操作ミス}, label={list:010_index_error}, language=Python]
#...
Q = int(input())
for _ in range(Q):
    R, L = map(int, input().split())
    total1 = ps1[R] - ps1[L-1]
    # ...
    print(f"{total1} {total2}")
\end{lstlisting}

\begin{lstlisting}[caption={カテゴリ3：累積和の作成ロジックの誤り}, label={list:010_cumsum_error}, language=Python]
n = int(input())
p1 = [0] * (n+1)
# ...
for i in range(n):
     c, p = map(int, input().split())
     p1[i] = p1[i-1]
     if c == 1:
         p1[i] += p
     # ...
\end{lstlisting}

\begin{lstlisting}[caption={カテゴリ5：最終的な結果の計算ミス}, label={list:010_calc_error}, language=Python]
# ...
class1 = [0]
class2 = [0]
# ... 
q = int(input())
for _ in range(q):
    l, r = map(int, input().split())
    print(class1[r] - class1[l -1], class1[r] - class2[l - 1])
\end{lstlisting}

\paragraph{グループ2：単純ループ構造の類似（カテゴリ1, 4）}\mbox{}\\
二つ目の混同パターンは,カテゴリ1（インデックス以外のクエリ処理ミス）とカテゴリ4（累積和を使用していない）である.
ソースコード\ref{list:010_incomplete}とソースコード\ref{list:010_tle}に示すように,両者は共に「入力を受け取り,単純なループを回す」という構造を持つ.
複雑な分岐や計算を持たないため,サイクロマティック複雑度などの特徴量が共に低くなり,アルゴリズムとしての正誤（未完成か,計算量不足か）にかかわらず「単純なコード」としてまとめられてしまう傾向にある.

\newpage

\begin{lstlisting}[caption={カテゴリ1：インデックス以外のクエリ処理ミス}, label={list:010_incomplete}, language=Python]
# ...
q = int(input())
l = [0] * q
r = [0] * q
for i in range(q):
     l[i], r[i] = map(int, input().split())
\end{lstlisting}

\begin{lstlisting}[caption={カテゴリ4：累積和を使用していない（TLE）}, label={list:010_tle}, language=Python]
# ...
for i, j in L_list:
    A_sum = sum(A[i:j+1])
    B_sum = sum(B[i:j+1])
    # ...
\end{lstlisting}

%\subsubsection{考察}
以上の分析から,手法1の限界について以下の結論が得られる.

\begin{enumerate}
    \item 本手法はコードの「構造」を特徴量とするため,ロジックが異なっていても構文構造が似ていれば,同一のクラスタとみなされてしまう.
    \item カテゴリ2, 3, 5のように,「インデックスが1ずれている」「変数が逆である」といった行レベルの局所的な意味論的誤りは,大域的な静的特徴量には反映されにくい.
    \item カテゴリ1, 4のように,コード構造が単純な場合,特徴量空間での距離が縮まりやすく,実装意図の違いを識別できない.
\end{enumerate}

したがって,誤答の原因特定レベルの分類を実現するためには,誤りのパターンを区別可能な特徴量設計または,コードの意味を捉えるLLM等の手法との組み合わせが必要不可欠であると言える.


\subsection{手法2による分類が有効であった事例と考察}
\label{subsec:method2_success}

本節では，手法2の有効性について考察する.
手法2は，前節で述べた手法1では分類が困難であった事例に対しても，高い精度で誤答パターンを識別することに成功した.
そこで，まず「問題J」における手法1との比較を行い，続いて特に高い分類精度を示した「問題BI」および「問題X」の事例を通して，手法2が有効に機能した要因を分析する.

\subsubsection{問題Jにおける結果と考察}

手法1において，構文構造の類似性から誤分類が発生していた「問題J」に対し，手法2を適用したところ，分類精度の明確な向上が確認された.手法1では，インデックス操作ミス（カテゴリ2）と作成ロジック誤り（カテゴリ3）が，共に「ループによる配列操作」という構造的類似性を持つため同一クラスタに混同されていた.これに対し手法2は，コードの表層的な構造ではなく，誤りの意味内容を正しく解釈できたことで，両者を明確に分離することに成功した.重要な点は，LLMが単にバグの箇所を特定しただけでなく，「誤りの内容を正しく説明できた」ことが，結果として正しいカテゴリへの分類を導いたという事実である.

出力結果におけるLLMの判断プロセスを以下に示す.

\begin{itemize}
    \item \textbf{カテゴリ2（インデックス操作ミス）への分類}: 
    LLMは「累積和の作成自体は正しいが，最終的な区間計算の式において $L$ と $R$ が逆転する」という論理的な矛盾を言語化した. この「論理矛盾」という文脈を抽出できたため，構造が似ている他のカテゴリと区別し，正しくカテゴリ2へ分類できた.
    
    \item \textbf{カテゴリ3（作成ロジック誤り）への分類}: 
    p1[i] = p1[i-1] といった記述に対し，LLMは「配列外参照のリスク」や「累積和の漸化式としての不整合」を説明として生成した. この説明に基づき，計算式の間違いではなく前処理の段階での誤りであると判断され，正確にカテゴリ3へ分類された.
\end{itemize}

なお，本節では特徴的な事例として問題Jの特定カテゴリを取り上げたが，他の多くのカテゴリにおいても，同様にLLMが誤りの内容を正しく言語化し，適切な分類へと導いていることが確認された．
以上の結果から，誤りの特定能力は，それ自体が独立した成果というよりも，高精度な誤答分類を実現するための「意味的特徴量の抽出機能」として極めて有効に機能したと言える.手法1が捉えきれなかった「コードの実装意図と実際の挙動の乖離」をLLMが言語化できたことが，分類精度の向上に直接的に寄与したと結論付けられる.



\subsubsection{問題BI概要と結果の考察}
問題BI（061 - Deck \cite{typical90_bi}）は,山札に対して条件に応じて「上に追加」「下に追加」「$x$番目を出力」という3種類のいずれかの操作を$Q$回行うシミュレーション問題である.
本問題の誤答コードは,表\ref{tab:error_categories}に示すように,主に以下の2つのカテゴリに分類された.

\begin{enumerate}
    \item \textbf{出力時のインデックス操作ミス}: クエリの指示通りに山札のインデックスを参照せず,入力された値そのものを出力してしまう等の誤り.
    \item \textbf{山札の操作・管理ミス}: 山札への追加操作（insertとappend）の挙動を逆にしてしまう等のロジック誤り.
\end{enumerate}

手法2で分類された具体的なコード例を以下に示す.
ソースコード\ref{list:bi_output_error}（カテゴリ1）とソースコード\ref{list:bi_operation_error}（カテゴリ2）は,どちらも制御構造は類似するが,誤りの性質が異なる.

ソースコード\ref{list:bi_output_error}では,配列 \texttt{X} を山札として操作しようとするが,出力処理において致命的なインデックス指定ミスがある.
本来は入力で与えられた「$x$ 番目」の要素を参照すべきところを,現在のクエリ番号であるループ変数 \texttt{i} をそのままインデックスとして使用しており,意図しない値を参照する.

一方,ソースコード\ref{list:bi_operation_error}においては,操作1と操作2の実装（appendとinsert）が逆であるというロジックの誤りがある.

\begin{lstlisting}[caption={カテゴリ1：出力時のインデックス操作ミス}, label={list:bi_output_error}, language=Python]
Q = int(input())
T = []
X = []

for i in range(Q):
  t, x = list(map(int,input().split()))
  T.append(t)
  X.append(x)

for i in range(Q):
  if T[i] == 1:
    X.insert(0, X[i])

  if T[i] == 2:
    X.insert(Q-1, X[i])

  if T[i] == 3:
    print(X[i])
\end{lstlisting}


\begin{lstlisting}[caption={カテゴリ2：山札の操作・管理ミス}, label={list:bi_operation_error}, language=Python]
Q = int(input())
s = []
ans = []

for i in range(Q):
    t, x = map(int, input().split())
    if t == 1:
        s.append(x)
    if t == 2:
        s.insert(0, x)
    if t == 3:
        ans.append(s[x-1])

for a in ans:
    print(a)
\end{lstlisting}

この事例における手法1と手法2の対比は示唆に富んでいる.
手法1では, 両者のコードは共に「条件分岐」と「リスト操作」の組み合わせで構成されており, 制御フローグラフや使用される演算子の種類といった構造的特徴が酷似するため, 同一クラスタに分類されてしまった.
一方で手法2は, 「山札の上」という自然言語の指示が「インデックス0への操作」に対応し, 「山札の下」が「末尾への操作」に対応するという意味的な対応関係を正しく認識できたため, 実装の矛盾を指摘できたと考えられる.


\subsubsection{問題X概要と結果の考察}
問題Xは, 長さ$N$の整数列$A$と$B$が与えられ, $A$の要素に対し「$+1$ または $-1$」する操作をちょうど $K$ 回行うことで, $A$を$B$に一致させることができるかを判定する問題である.
正解するためには, 以下の2つの条件を満たす必要がある.
\begin{enumerate}
    \item 差分の総和（$\sum |A_i - B_i|$）が $K$ 以下であること.
    \item 残りの操作回数（$K - \sum |A_i - B_i|$）が偶数であること.
\end{enumerate}

本問題の誤答は, 表\ref{tab:error_categories}に示すように, 主に「偶奇判定の記述漏れ」や「絶対値計算の欠落」などに分類された.

\paragraph{意味的解釈による分類の成功} \mbox{}\\
本問題においても, 手法2は高い分類精度を記録した. 特筆すべきは,「条件式の不足」という不可視の誤りを検出できた点である.

例えば, 「差分の総和が $K$ 以下か」のみを判定し, 偶奇判定を行っていない誤答コードにおいて,静的解析の観点からは, 正解コードと誤答コードは共に「ループで差分を計算し, 最後にif文で判定する」という同一の構造を持つため, この「条件式が一つ足りない」という差異を距離として捉えることは困難である.

しかし手法2は, 問題文中の「ちょうど $K$ 回」という記述から「過剰な回数分は $+1$ と $-1$ で相殺する必要があるため, 残回数は偶数でなければならない」という論理を導出し, コード内にその判定ロジックが存在しないことを指摘することで, 正しく「判定条件の記述漏れ」カテゴリへと分類した.

\subsubsection{有効性}
\label{subsubsec:discussion_explicit}

問題J,BI,Xなど, 手法2が特に有効であった事例を総括すると, ある共通点が浮かび上がる.
これらの問題では, 「問題文の指示」と「コードの実装」の対応関係が明確な点である.
問題BIでは,「上に追加」「下に追加」といった操作手順が, 具体的なデータ構造の操作と直結する.問題Xでは,「操作回数がちょうど $K$ 回」という条件が, 数学的な制約を厳密に規定する.
そのため, LLMはプロンプトとして与えられた問題文から期待されるロジックを構築し, それと提出コードとの間に生じている乖離を検出しやすいことが考えられる.



\subsection{手法2による分類が困難であった事例と考察}
\label{subsec:case_study_bo}

手法2は多くの問題で高い精度を示したが, 一部の問題では分類が安定しない, あるいは誤った推論に基づく分類が行われる事例が見られた.
本節では, その代表例として以下の2つの問題を取り上げ, LLMを用いた分類における課題を詳細に分析する.

\begin{itemize}
    \item \textbf{問題BO（067 - Base 8 to 9 \cite{typical90_bo}）}:
    複数の誤りが混在するコードにおいて, LLMが「誤りの優先度」を正解ラベルの意図通りに判断できず, 分類結果が揺らいだ事例である.
    \item \textbf{問題V（022 - Cubic Cake \cite{typical90_v}）}:
    LLMが数学的な事実やアルゴリズムの挙動に対して事実誤認を起こし, 誤った根拠に基づいて不適切なカテゴリへ分類してしまった事例である.
\end{itemize}

以下, 各問題について具体的なコード例を挙げながら, 分類失敗の要因とその背景にあるLLMの特性について考察する.
\subsubsection{問題BO概要と結果の考察}
問題BO（067 - Base 8 to 9 \cite{typical90_bo}）は, 8進法の整数 $N$ に対し, 「10進数変換」「9進数変換」「数字8を5へ置換」「8進数とみなす」という一連の操作を $K$ 回行うシミュレーション問題である.
本問題の誤答コードは, 表\ref{tab:error_categories}に示すように, 主に以下のカテゴリに関連する誤りを含んでいる.

\begin{enumerate}
    \item \textbf{$N=0$ 等のコーナーケース処理漏れ}: 入力が0の場合のループ条件や出力の不備.
    \item \textbf{$n$進数変換処理の実装ミス}: 基数変換のロジック自体や, 桁数処理の固定化などの誤り.
\end{enumerate}

手法2による分類が困難であった具体的なコード例を以下に示す.
ソースコード\ref{list:bo_code_ambiguous}は, 一見すると単純な実装に見えるが, 分類器を迷わせる複数の要因を含んでいる.単なる条件分岐の漏れよりも, 「桁数を19桁に固定する」という実装方針の誤りの方がアルゴリズムとして致命的であると判断したので、正解ラベルではカテゴリ4（$n$進数変換処理の実装ミス）に分類する.しかし, 手法2による判定では, $N=0$ の場合に停止しないという具体的な挙動に注目が集まりやすく, カテゴリ1（コーナーケース処理漏れ） へ誤分類される事例が多く見られた.我々の期待としては, 局所的なバグ（$N=0$）よりも, コード全体を支配する根本的なロジックの誤りを優先度高く評価し, カテゴリ4へと導くことを理想としていたが, LLMにとっては両者の「誤りの重み」を比較判断することが困難であったと考えられる.

\newpage

\begin{lstlisting}[caption={カテゴリ1と4の境界：$N=0$ の処理漏れと固定桁ループ}, label={list:bo_code_ambiguous}, language=Python]
n, k = map(int,input().split())

for j in range(k):
    N = 0
    for l in range(19):
        N += n%10*(8**l)
        n = n//10
        if n == 0:
            break

    s = ""
    for i in range(19):
        s = str(N%9)+s
        N = N//9
    s = s.replace("8","5")
    n = int(s)

print(n)
\end{lstlisting}

\subsubsection{問題V概要と結果の考察}
問題V（022 - Cubic Cake \cite{typical90_v}）は, 幅 $A$, 高さ $B$, 奥行き $C$ の直方体を, 各面に平行な切断のみですべて一辺が等しい立方体に分割する際の, 最小切断回数を求める問題である.
gをA,B,Cの最大公約数としたとき, 最小切断回数は以下の式で求められる.
\[
(A//g - 1) + (B//g - 1) + (C//g - 1)
\]

本問題の誤答コードは, 表\ref{tab:error_categories}に示すように, 主に以下のカテゴリに関連する誤りを含んでいる.
\begin{enumerate}
    \item \textbf{最大公約数の算出ミス}: ライブラリの誤用や自作関数のロジックミス.
    \item \textbf{浮動小数点演算による誤差}: 割り算（/）を使用してしまい, 桁落ちや誤差が生じる.
    \item \textbf{GCDを使用した場合の最小回数算出ミス}: 式の立て方や演算子の優先順位の誤り.
\end{enumerate}

手法2による分類において, 致命的な課題が確認された具体的なコード例を以下に示す.
ここでは, 「本当の誤り」を指摘できず, 「事実と異なる仕様」を根拠に誤分類を行った事例を取り上げる.

ソースコード\ref{list:v_hallucination_gcd}は, Python 3.9以降でサポートされている「3引数の \texttt{math.gcd}」を使用するが, 計算式の括弧不足という致命的なバグを含んでいる.
これに対しLLMは, 計算式の誤り（カテゴリ3）を指摘せず, 「\texttt{math.gcd} は引数を2つしか取れない」という事実誤認を行い, その結果として カテゴリ1（最大公約数の算出ミス） に誤分類した.

また, ソースコード\ref{list:v_hallucination_float}は, 浮動小数点除算を行っているため カテゴリ2（浮動小数点演算による誤差） に分類されるべき事例である.
しかしLLMは, 浮動小数点の危険性を看過して「正解コードである」と誤判定したり, あるいは全く関係のない「入出力のミス」等の理由を捏造して不適切なカテゴリへ分類する挙動を示した.

\begin{lstlisting}[caption={ハルシネーション：括弧不足を見逃し, 正しい構文を誤りと指摘}, label={list:v_hallucination_gcd}, language=Python]
import math

A,B,C = map(int,input().split())
n = math.gcd(A,B,C)

print((A+B+C//n)-3)
\end{lstlisting}

\begin{lstlisting}[caption={評価の揺らぎ：浮動小数点誤差の誤判定}, label={list:v_hallucination_float}, language=Python]
import math

A,B,C = map(int,input().split())
g = math.gcd(math.gcd(A, B), C)

print(int((A/g-1)+(B/g-1)+(C/g-1)))
\end{lstlisting}


\subsubsection{課題}
\label{subsec:method2_discussion_summary}

本節で詳述した2つの事例は, 手法2を用いたコード評価において, 単なる分類精度の数値からは読み取れない本質的な課題を浮き彫りにする.
まず, 問題BOの事例からは, 複合的な誤りに対する「優先度判断」の難しさが確認された.
実際の誤答コードでは, 「アルゴリズムの破綻」と「特定条件のバグ」が混在することが多い.
人間であれば前者をより重大な誤りとみなすが, LLMはその重み付けを適切に行えず, 表面的な挙動に引きずられて分類が揺らぐ傾向にある.
これは, 複雑な誤りを含むコードに対して, 単一の正解ラベルを求めようとする現在の評価定義自体の限界を示唆する.

さらに深刻な課題として, 問題Vでは「事実誤認」と「論理誤りの見落とし」という二重のリスクが顕在化した.
LLMは必ずしもコードの論理的な正当性を厳密に検証するわけではなく, 「括弧不足」という真の誤りを見逃しつつ, 「言語仕様に関する虚偽」を根拠に正しい記述を修正させようとする危険な挙動が確認された.
このような「もっともらしい嘘」を含んだフィードバックは, 学習者の知識習得を阻害するため, 教育システムへの導入において重大な障壁となる.

\section{本章まとめ}
\label{sec:chapter_summary_comparison}

本章で検証した手法1と手法2の有効性と課題を以下に整理する.

\begin{itemize}
    \item \textbf{手法1}
    \begin{itemize}
        \item \textbf{有効性}
        \begin{itemize}
            \item \textbf{構造の識別}: 全探索と数学的解法など, アルゴリズムの方針自体が異なるものを明確に分離できる.
            \item \textbf{再現性}: 常に一定の結果が得られる.
        \end{itemize}
        \item \textbf{課題}
        \begin{itemize}
            \item \textbf{微細な論理バグ}: ループ構造が同じであれば, インデックスのズレ等の局所的な誤りを識別できない.
        \end{itemize}
    \end{itemize}

    \item \textbf{手法2}
    \begin{itemize}
        \item \textbf{有効性}
        \begin{itemize}
            \item \textbf{意味の理解}: 変数名や文脈から, 実装者の意図や不可視の条件漏れを指摘できる.
        \end{itemize}
        \item \textbf{課題}
        \begin{itemize}
            \item \textbf{信頼性の欠如}: 複数のバグに対する優先度判断が揺らぐほか, 嘘の仕様を教えるハルシネーションのリスクがある.
        \end{itemize}
    \end{itemize}
\end{itemize}

\subsection{結論}

以上の検証から, 両手法はそれぞれ異なる役割と限界を持つことが明らかとなった.
手法1は, 問題Jのように微細な論理差分の検出には不向きであるものの, 問題AGのように学習者が選択した「アルゴリズムの方針」を構造的に分類することにおいては高い信頼性を持つ.
一方, 手法2は, 問題BIやXのように構造に現れない文脈的な誤りを検出可能であるが, その判定は確率的であり, 解釈の揺らぎや事実誤認のリスクを内包する.
したがって, 高精度な自動評価を実現するためには, 単に両者を並列に扱うのではなく, 手法1による「解法の大別（構造の固定）」を前提とし, その上で手法2による「論理の検証」を行うといった, 評価の粒度に応じた階層的なアプローチが必要であると結論付けられる.
