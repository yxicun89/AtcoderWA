\chapter{実験方法}
\label{chap:methodology}

\section{実験目的}
本研究の目的は,プログラミング演習における誤答ソースコードを機械的に分類し,教育支援に役立てることである.
本実験では,そのための具体的な手法として,従来手法である静的解析に基づくクラスタリング手法（Asanas Cluster）と,近年急速に発展しているLLMを用いた分類手法の2つを取り上げ,それぞれの分類精度および特性を比較検証する.

具体的には,同一の誤答データセットに対して両手法を適用し,どちらの手法がより高精度に誤答パターンを分類できるかを定量的に評価する.
この比較を通じて,誤答コードの自動分類システムを構築する上で,どちらのアプローチがより実用的かつ有効であるかを明らかにすることを目的とする.

\section{実験環境}
本実験は,以下のハードウェアおよびソフトウェア環境下で実施した.
実験の再現性を担保するため,詳細なバージョン情報を記載する.

\subsection{ハードウェア・OS構成}
\begin{itemize}
    \item \textbf{OS}: Windows 11
    \item \textbf{実行環境}: WSL2 (Windows Subsystem for Linux 2) - Ubuntu Environment
\end{itemize}

\subsection{ソフトウェア・ライブラリ}
静的解析に基づく特徴抽出,クラスタリング,および評価指標の算出には,プログラミング言語Pythonを用いた.
主要な使用ライブラリとその用途は以下の通りである.

\begin{itemize}
    \item \textbf{Python}: 3.12.3
    \item \textbf{PyJoern}: ソースコードの静的解析エンジン.制御フローグラフ (CFG) およびデータフローグラフ (DFG) の生成に使用.
    \item \textbf{NetworkX}: グラフ構造の解析.循環的複雑度やパス数の算出に使用.
    \item \textbf{scikit-learn}: K-meansクラスタリングの実装,および評価指標（適合率,再現率,F値）の計算に使用.
    \item \textbf{SciPy}: ハンガリアンアルゴリズム（線形割り当て問題）の実装.クラスタリング結果と正解ラベルの最適マッチングに使用.
    \item \textbf{NumPy / Pandas}: 数値計算およびデータ処理に使用.
\end{itemize}

また,比較対象となる大規模言語モデルを用いた分類には,OpenAI社が提供するAPIを使用した.

\begin{itemize}
    \item \textbf{使用モデル}: GPT-4o
\end{itemize}

\section{対象データ}
本実験では,オンラインジャッジシステム「AtCoder」上で公開されている問題セット「競プロ典型90問」を対象とした.
この問題セットは,競技プログラミングにおいて頻出するアルゴリズムや実装テクニックを網羅しており,誤答パターンの分析に適していると考えられる.

\subsection{選定問題とデータ規模}
「競プロ典型90問」の中から,難易度「★2」に設定されている問題計10問を選定した.
各問題について,判定結果が「WA (Wrong Answer)」または「TLE (Time Limit Exceeded)」となった提出コードを収集した.
データの収集にあたっては,1つの問題につき100件の誤答コードを抽出した.この際,コーディングスタイルの多様性を確保するため,同一ユーザーによる提出は重複して取得せず,100名の異なるユーザーによるソースコードを対象とした.
したがって,本実験で使用するデータの総数は,10問 $\times$ 100件の計1,000件である.

\subsection{データのフィルタリングと選定基準}
収集した誤答コードの中には,本研究が目的とする「アルゴリズムや論理の誤り」の分析に適さないデータが含まれている可能性があるため,以下の基準に基づきフィルタリングを行った.

\begin{enumerate}
    \item \textbf{デバッグ出力の除外}:
    AtCoderのジャッジシステム上,回答に関係のない余分な \texttt{print} 文が含まれている提出は,収集段階で除外した.

    \item \textbf{出力形式ミスの除外}:
    アルゴリズムや解法自体は正しいものの,空白区切りで出力すべきリストを,Pythonのリスト形式 \texttt{[...]} のまま出力しているなど出力形式の不備によってWAとなっているコードは,本研究の分析対象である論理的な誤答ではないため排除した.

    \item \textbf{コンパイル可能性}:
    構文エラーで実行不可能なコードは対象外とし,コンパイルおよび実行が可能でありながら,論理的な誤りまたは実行時間超過が発生しているコードのみを対象とした.

    \item \textbf{コメントアウトの削除}:
    前処理として,コード内のコメント記述をすべて削除した.
    手法1においてはコメントの有無は解析結果に影響しないが,手法2（LLM）においては,コメント内にアルゴリズムのヒントが含まれていた場合に推論が有利になったり,逆にコメントアウトされたデバッグコードを論理的な誤りとして誤認したりする可能性がある.これらのバイアスを排除し,純粋なコードロジックのみによる公平な比較を行うために適用した.
\end{enumerate}

\subsection{正解ラベルの作成}
収集した誤答コードに対する評価の基準を作成するため,各問題のソースコードを目視で確認し,手動による分類を行った.
具体的な手順として,まず収集したコードに見られる具体的な誤りを洗い出し,それらを誤答の原因や種類に基づいて一般化することで,各問題に対して3〜5個程度の主要な誤答カテゴリを定義した.
各問題において定義した誤答カテゴリの内訳を表\ref{tab:error_categories}に示す.

\begin{longtable}{|l|p{10cm}|}
    \caption{各問題における誤答カテゴリの定義}
    \label{tab:error_categories} \\

    % --- 最初のページのヘッダー ---
    \hline
    \textbf{問題ID} & \textbf{定義した誤答カテゴリ} \\
    \hline
    \endfirsthead

    % --- 2ページ目以降のヘッダー（続きとわかるようにする） ---
    \multicolumn{2}{l}{\footnotesize （前ページの続き）} \\
    \hline
    \textbf{問題ID} & \textbf{定義した誤答カテゴリ} \\
    \hline
    \endhead

    % --- 各ページの終わりのフッター ---
    \hline
    \multicolumn{2}{r}{\footnotesize 次ページへ続く} \\
    \endfoot

    % --- 最終ページの終わりのフッター ---
    \hline
    \endlastfoot

    % --- データ本体 ---
    \textbf{aa} &
    1. ハッシュ衝突による誤り \newline
    2. 二分探索の実装およびロジックの間違い \newline
    3. 出力形式または出力内容の間違い \newline
    4. 名簿管理（データ構造）における操作ミス \newline
    5. 重複チェック処理における条件漏れ \\
    \hline

    \textbf{ag} &
    1. 点灯個数の探索・カウント処理の誤り \newline
    2. 特定条件下（コーナーケース等）の考慮漏れ \\
    \hline

    \textbf{bc} &
    1. 全探索による実行時間超過 (TLE) \newline
    2. 組み合わせ選択後の計算ロジックの誤り \newline
    3. 組み合わせの作成・選択自体の間違い \newline
    4. 計算以外の制約条件確認ミス \newline
    5. 剰余計算（mod計算）処理の誤り \\
    \hline

    \textbf{bi} &
    1. 出力時のインデックス操作ミス \newline
    2. 山札（Deque等）の操作・管理ミス \\
    \hline

    \textbf{bo} &
    1. $N=0$ 等のコーナーケース処理漏れ \newline
    2. 再帰関数による計算エラー \newline
    3. 出力形式または内容の間違い \newline
    4. $n$進数変換処理の実装ミス \\
    \hline

    \textbf{bz} &
    1. グラフ探索の実装不備によるTLE \newline
    2. 「頂点がちょうど1個」の条件判定ミス \newline
    3. 隣接リスト・配列作成時のミス \\
    \hline

    \textbf{d} &
    1. 出力時のインデックス操作ミス \newline
    2. 累積和の作成ロジックの誤り \newline
    3. 累積和を使用していない（アルゴリズム選択ミス） \newline
    4. 累積和を使用しているが計算方法に誤りがある \\
    \hline

    \textbf{j} &
    1. インデックス以外のクエリ処理ミス \newline
    2. クエリ処理時のインデックス操作ミス \newline
    3. 累積和の作成ロジックの誤り \newline
    4. 累積和を使用していない \newline
    5. 最終的な結果の計算ミス \\
    \hline

    \textbf{v} &
    1. 最大公約数(GCD)の算出ミス \newline
    2. 浮動小数点演算による誤差 \newline
    3. GCDを使用しない場合の最小回数算出ミス \newline
    4. GCDを使用した場合の最小回数算出ミス \\
    \hline

    \textbf{x} &
    1. 判定条件の記述漏れ \newline
    2. 条件判定ロジックの誤り \newline
    3. 差分計算におけるミス \\

\end{longtable}




\section{グラフ生成の妥当性と基本ブロックの確認}
\label{sec:graph_validation}

第\ref{chap:proposal}章（提案手法）で述べた通り,本研究の手法1ではソースコードから直接的に制御フローグラフ(CFG)を生成し,基本ブロック単位での解析を行っている.
この生成プロセスの妥当性,および先行研究で行われていた収縮処理が本手法の生成プロセスにおいて自動的に達成されていることを確認するため,本実験環境における実際の解析例を図\ref{fig:cfg_example}に示す.

図\ref{fig:cfg_example}(a)は単純な条件分岐を含むソースコードの例であり,(b)は本手法の実装（PyJoern）によって生成されたCFGである.

\begin{figure}[tbp]
    \centering
    % --- 上段：ソースコード ---
    \begin{minipage}[c]{0.95\textwidth}
        \centering
\begin{lstlisting}[basicstyle=\ttfamily\small, frame=single, xleftmargin=5mm, caption={入力ソースコード例}]
def classify_sum(a, b):
    x = a * 10
    y = b + 5
    total = x + y

    if total > 50:
        print("Large")
    else:
        print("Small")
\end{lstlisting}
    \end{minipage}

    \vspace{2mm}
    (a) 入力ソースコード例
    \vspace{5mm}

    % --- 下段：CFG画像 ---
    \begin{minipage}[c]{0.95\textwidth}
        \centering
        % グラフの横幅は見やすさに応じて調整してください
        \includegraphics[width=0.85\textwidth]{src/pyjoern_cfg.png}
    \end{minipage}

    \vspace{2mm}
    (b) 生成されたCFG

    \caption{ソースコードと生成された基本ブロック単位のCFGの対応}
    \label{fig:cfg_example}
\end{figure}

図\ref{fig:cfg_example}(b)を確認すると,変数定義である \texttt{x=10}, \texttt{y=20}, \texttt{total=x+y} という一連の連続した命令が,個別のノードに分割されることなく,単一の基本ブロックとして統合されていることがわかる.
また,そのブロックから \texttt{if} 文による条件分岐が正しくエッジとして表現されている.

この結果から,本実験の環境において,\textbf{先行研究が手動で行っていた「冗長な遷移の収縮」が基本ブロックの構築として内包されている}ことが確認できる.したがって,生成されたグラフはアルゴリズムの構造的特徴を抽出するために十分な抽象度と妥当性を有していると言える.

\section{実験手順}
本実験では,前節で述べた誤答コード群に対し,静的解析に基づく手法（Asanas Cluster）と大規模言語モデル（LLM）に基づく手法のそれぞれを適用し,分類性能を検証する.
両手法において,最終的な出力と正解ラベルの照合プロセスが異なるため,以下にそれぞれの手順を詳述する.

\subsection{手法1: 静的解析とクラスタリングによる分類手順}
本手法は,ソースコードから抽出した特徴量に基づきK-means法により分類を行い,その結果を正解カテゴリに割り当てるアプローチである.

\subsubsection{1. 特徴量の抽出および前処理}
分類の入力データとしては,前章の表\ref{tab:features}で定義した\textbf{CFGおよびDFGに基づく計11次元の特徴量ベクトル}を用いる.

特に\texttt{paths}（グラフ内の異なるパスの数）の算出においては,ループや分岐構造を適切に反映させるため,「各ノードを最大2回まで訪問してよい」という制約ルールを設けている.

なお,K-means法は特徴量の値の範囲（スケール）の違いによる影響を受けやすいため,先行研究と同様に,前処理としてすべての特徴量が平均0,分散1となるように標準化を行った上で実験に使用した.


\subsubsection{2. K-meansによるクラスタリング}
標準化されたデータに対し,K-means法を適用して分類を行った.クラスタ数 $K$ は,各問題に対して事前に定義した正解カテゴリ数（2〜5個）と一致するように設定した.
この段階で,各コードは機械的に \texttt{cluster1}, \texttt{cluster2} \dots といったクラスタIDに分類される.

\subsubsection{3. ハンガリアンアルゴリズムによる正解ラベルとの対応付け}
本実験では,K-meansの初期値として各正解カテゴリのセントロイドを与えてクラスタリングを行っている.
しかし,クラスタリングの過程で重心位置が更新されるため,最終的に出力されるクラスタIDと正解ラベルの対応関係は必ずしも初期状態と一致するとは限らない.

そこで,分類精度を正しく評価するために,形成された各クラスタと正解カテゴリの最適な対応付けを行う必要がある.
本実験では,単純な「多数決」ではなく,\textbf{ハンガリアンアルゴリズム}を用いて「全体として最も正解数が多くなる（誤分類が最小になる）組み合わせ」を算出した.

\textbf{単純な多数決の問題点:}
表\ref{tab:greedy_fail}に示すように,単純に各クラスタ内で最も多いカテゴリを採用する貪欲法と,割り当ての競合により全体最適が損なわれる場合がある.

\begin{table}[tbp]
  \centering
  \caption{割り当て手法による正解数の比較例}
  \label{tab:greedy_fail}
  \begin{tabular}{lcc}
    \toprule
     & \textbf{カテゴリA (得意)} & \textbf{カテゴリB (苦手)} \\
    \midrule
    \textbf{クラスタ0} & 100 & 99 \\
    \textbf{クラスタ1} & 90 & 5 \\
    \bottomrule
  \end{tabular}
\end{table}

表\ref{tab:greedy_fail}の例では,貪欲法だと総正解数は105（クラスタ0→A, クラスタ1→B）にしかならないが,ハンガリアンアルゴリズムを用いれば,総正解数を189（クラスタ0→B, クラスタ1→A）まで最大化できる.
本手法では,このアルゴリズムを用いて最適な1対1の対応関係を決定し,その結果に基づいて精度評価を行った.

\subsection{手法2: LLMによる分類手順}
本手法は,LLMにコードと分類基準を提示し,どのカテゴリに該当するかを直接判断させるアプローチである.

\begin{enumerate}
    \item \textbf{プロンプトの構築}:
    各問題のソースコードと,前節で定義した「誤答カテゴリのリスト」をプロンプトとして構築した.
    LLM（GPT-4o）に対し,入力されたコードがリスト内のどのカテゴリに最も適合するかを選択させた.

    \item \textbf{分類結果の出力}:
    LLMは,コードの内容を解析し,その誤答原因に合致すると判断したカテゴリIDを出力する.ここでは,物理的なディレクトリ移動は行わず,各ファイルに対する予測ラベルとして記録した.

    \item \textbf{正解データとの照合}:
    LLMによる予測結果の正当性を検証するため,ファイル名（\texttt{submission\_ID}）をキーとした正解ラベルの辞書データを作成し,照合を行った.
    具体的には,各ファイルが実際に所属すべき正解カテゴリと,LLMが出力したカテゴリIDが一致しているかを確認した.
\end{enumerate}

\section{評価指標}
本実験では,手法1(Asanas Cluster)と手法2(LLM)の分類性能を定量的に比較するため,以下の指標を用いる.
分類結果の妥当性を評価するため,正解カテゴリを「正解」,分類されたクラスタ内のファイルを「予測」として定義する.

\subsection{適合率 (Precision)}
分類されたクラスタの中に,どれだけ「正解以外のノイズ」が含まれていないかを表す指標（純度）である.
\begin{equation}
  \text{Precision} = \frac{\text{正しく分類されたファイル数}}{\text{そのクラスタに含まれる全ファイル数}}
\end{equation}
この値が1に近いほど,誤検知（ノイズ）が少ないことを意味する.

\subsection{再現率 (Recall)}
本来そのカテゴリに含まれるべきファイルを,どれだけ網羅（一致）できたかを表す指標である.
\begin{equation}
  \text{Recall} = \frac{\text{正しく分類されたファイル数}}{\text{正解カテゴリに含まれる全ファイル数}}
\end{equation}
この値が1に近いほど,取りこぼしが少ないことを意味する.

\subsection{F値 (F1-score)}
適合率と再現率の調和平均である.精度の高さ（ノイズの少なさ）と網羅性（取りこぼしのなさ）のバランスを表す総合的な指標となる.
\begin{equation}
  \text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}
適合率と再現率のどちらか一方が極端に低い場合,F値は大きく低下するため,バランスの取れた分類ができているかを判定するのに適している.
